{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4126b2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import pprint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fb7735",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "afe1476b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the OpenAI API key for making OpenAI requests\n",
    "# Similar to above, the key is fetched from the environment variables\n",
    "# 'openai' is a Python client library for accessing OpenAI's APIs, so this line sets the authentication to be used for all subsequent requests through 'openai'\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc814ece",
   "metadata": {},
   "source": [
    "## Function: `generate_openai_response()`\n",
    "\n",
    "This function generates a response from the specified OpenAI model. It accepts a prompt and model name as input and sends these to OpenAI's API to get a generated response. Here's a breakdown of its arguments and workflow:\n",
    "\n",
    "- **Arguments**\n",
    "  - `prompt`: The input text which is to be completed by the model.\n",
    "  - `model` (default 'gpt-3.5-turbo'): The identifier of the language model to use. This defaults to 'gpt-3.5-turbo' if no model is explicitly provided.\n",
    "  - `**kwargs`: Additional keyword arguments that can be passed to the `openai.ChatCompletion.create()` method.\n",
    "\n",
    "- **Workflow**\n",
    "  - The function starts by calling `pretty_print(prompt)` to print the prompt text.\n",
    "  - It then calls `openai.ChatCompletion.create()` with the specified model and prompt. This sends a request to the OpenAI API, which returns a chat completion response.\n",
    "  - The function returns this chat completion response. The returned object contains the generated message, along with other metadata.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d71d83ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print(data, indent=0):\n",
    "    pp = pprint.PrettyPrinter(indent=indent)\n",
    "    for item in data:\n",
    "        print(item['role'] + ': ' + item['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "bc57fa24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_openai_response(prompt, model='gpt-3.5-turbo', **kwargs):\n",
    "    if model in ('gpt-3.5-turbo', 'gpt-4'):\n",
    "        pretty_print(prompt)\n",
    "\n",
    "        chat_completion = openai.ChatCompletion.create(\n",
    "            model=model,\n",
    "            messages=prompt,\n",
    "            **kwargs\n",
    "        )\n",
    "        return chat_completion\n",
    "    elif 'ada' in model:\n",
    "\n",
    "        # Generate a completion using the fine-tuned model\n",
    "        res = openai.Completion.create(\n",
    "            model=model, \n",
    "            prompt=prompt,\n",
    "            **kwargs\n",
    "        )\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a5da4ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'you are such a loser! I cannot believe you are even here.'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6cc5245",
   "metadata": {},
   "source": [
    "# Class A: the model knows enough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "253bbe18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "system: You are a bot that classifies whether a given piece of text is toxic or not. Use \"Toxic\" or \"Non-Toxic\"\n",
      "user: Text: you are such a loser! I cannot believe you are even here.\n",
      "Label:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Toxic'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A simple classifier with instructions\n",
    "\n",
    "generate_openai_response(\n",
    "    [\n",
    "        {'role': 'system', 'content': 'You are a bot that classifies whether a given piece of text is toxic or not. Use \"Toxic\" or \"Non-Toxic\"'}, \n",
    "        {'role': 'user', 'content': f'Text: {text}\\nLabel:'}\n",
    "    ]\n",
    ").choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ae5460",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d6bb0a6d",
   "metadata": {},
   "source": [
    "# Class B: the model has the capcity to learn in-context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfacc7a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cab58a85",
   "metadata": {},
   "source": [
    "## With chain of thought"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8af57114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "system: You are a bot that classifies whether a given piece of text is toxic or not. Use \"Toxic\" or \"Non-Toxic\"\n",
      "user: Use this reasoning:\n",
      "Text: (the input text)\n",
      "Reasoning: (an explanation of why the language is toxic)\n",
      "Label: (Either \"Non-Toxic\" or \"Toxic\")\n",
      "\n",
      "Text: you are such a loser! I cannot believe you are even here.\n",
      "Reasoning: The language used in this text is derogatory and demeaning. It includes personal attacks and negative judgment towards the recipient, calling them a \"loser.\" The tone is insulting and intended to provoke a negative emotional response.\n",
      "\n",
      "Label: Toxic\n"
     ]
    }
   ],
   "source": [
    "# Prompting the LLM to include chain of thought increases the number of input/output tokens\n",
    "#  but often leads to more consistent results and with a more transparent feature\n",
    "print(generate_openai_response(\n",
    "    [\n",
    "        {'role': 'system', 'content': 'You are a bot that classifies whether a given piece of text is toxic or not. Use \"Toxic\" or \"Non-Toxic\"'}, \n",
    "        {'role': 'user', 'content': f'Use this reasoning:\\nText: (the input text)\\nReasoning: (an explanation of why the language is toxic)\\nLabel: (Either \"Non-Toxic\" or \"Toxic\")\\n\\nText: {text}'}\n",
    "    ]\n",
    ").choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470bd0f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5d3279c1",
   "metadata": {},
   "source": [
    "# Class C: the model does not know enough - Fine-tuning with OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "24cbe067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This model was fine-tuned in my new LLM book here: https://learning.oreilly.com/library/view/quick-start-guide/9780138199425\n",
    "#  it takes in a product review and assigns a number of stars from 1-5\n",
    "\n",
    "prompt = '''Great pieces of jewelry for the price\n",
    "\n",
    "Great pieces of jewelry for the price. The 6mm is perfect for my tragus piercing. I gave four stars because I already lost one because it fell out! Other than that I am very happy with the purchase!\n",
    "\n",
    "###\n",
    "\n",
    "'''\n",
    "\n",
    "res = generate_openai_response(prompt, model='ada:ft-personal-2023-05-08-16-25-48', \n",
    "                                     temperature=0, max_tokens=1, logprobs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "4583af4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Star: 4\n",
      "Probabilities:\n",
      " 4: 0.9959\n",
      " 5: 0.0025\n",
      " 3: 0.0013\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "# Extract logprobs from the API response\n",
    "probs = []\n",
    "logprobs = res.choices[0].logprobs.top_logprobs\n",
    "# Convert logprobs to probabilities and store them in the 'probs' list\n",
    "for logprob in logprobs:\n",
    "    _probs = {}\n",
    "    for key, value in logprob.items():\n",
    "        _probs[key] = math.exp(value)\n",
    "    probs.append(_probs)\n",
    "# Extract the predicted category (star) from the API response\n",
    "pred = res['choices'][0].text.strip()\n",
    "# Nicely print the prompt, predicted category, and probabilities\n",
    "print(\"Predicted Star:\", pred)\n",
    "print(\"Probabilities:\")\n",
    "for prob in probs:\n",
    "    for key, value in sorted(prob.items(), key=lambda x: x[1], reverse=True):\n",
    "        print(f\"{key}: {value:.4f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19dd1fa6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc6441e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e6d77d2e",
   "metadata": {},
   "source": [
    "# Zero-Shot Text Classification with BART-MNLI\n",
    "\n",
    "Welcome to this Jupyter notebook where we will be exploring Zero-Shot Text Classification using the BART-MNLI model.\n",
    "\n",
    "## Overview\n",
    "\n",
    "In the field of Natural Language Processing (NLP), zero-shot learning refers to the ability of a model to understand and make predictions on data it has never seen during training. This is accomplished by learning a rich semantic representation of language from the training data, which can then be generalized to new, unseen classes.\n",
    "\n",
    "In this notebook, we'll use the `transformers` library, developed by Hugging Face, which gives us a high-level API to LLMs.\n",
    "\n",
    "## BART and MNLI\n",
    "\n",
    "BART (Bidirectional and Auto-Regressive Transformers) is a Transformer-based model that was trained by Facebook. Unlike traditional transformer models that are trained to predict the next token in a sequence, BART is trained to reconstruct the original sequence after it has been altered.\n",
    "\n",
    "Multi-Genre Natural Language Inference (MNLI) is a large-scale, crowd-sourced entailment classification task. Models are trained to predict whether a given sentence can be inferred from another given sentence, providing a strong training signal for sentence-level understanding.\n",
    "\n",
    "The `facebook/bart-large-mnli` model that we will be using in this notebook is a version of the BART model fine-tuned on the MNLI dataset. As such, it is capable of understanding sentence-level semantic relationships, making it a good candidate for zero-shot text classification tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e3383307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequence': 'you are such a loser! I cannot believe you are even here.',\n",
       " 'labels': ['Toxic', 'Non-Toxic'],\n",
       " 'scores': [0.8756353259086609, 0.12436465919017792]}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the required pipeline function from the transformers library\n",
    "# This function allows us to easily instantiate a pre-trained model for various NLP tasks\n",
    "from transformers import pipeline\n",
    "\n",
    "# Initialize the zero-shot-classification pipeline using the BART-MNLI model\n",
    "# Zero-shot classification allows us to classify text into labels that the model has never seen during training.\n",
    "# BART-MNLI is a model trained on the Multi-Genre Natural Language Inference (MNLI) dataset and fine-tuned on BART architecture,\n",
    "# which is used to predict the labels of unseen classes.\n",
    "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
    "\n",
    "# Define the possible labels for the classification task\n",
    "# In this case, the two possible labels are 'Toxic' and 'Non-Toxic'\n",
    "candidate_labels = ['Toxic', 'Non-Toxic']\n",
    "\n",
    "# The classifier is used to classify the provided text into one of the candidate labels.\n",
    "# The parameter 'multi_label' is set to False, which means the classifier will assign only one label to the input text,\n",
    "# choosing the one with the highest score.\n",
    "classifier(text, candidate_labels, multi_label=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "d8f8914a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9811c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290fc542",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
